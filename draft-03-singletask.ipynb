{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 3494,
          "sourceType": "datasetVersion",
          "datasetId": 2050
        },
        {
          "sourceId": 6488923,
          "sourceType": "datasetVersion",
          "datasetId": 3749709
        },
        {
          "sourceId": 8456560,
          "sourceType": "datasetVersion",
          "datasetId": 5040201
        },
        {
          "sourceId": 8456642,
          "sourceType": "datasetVersion",
          "datasetId": 5040267
        },
        {
          "sourceId": 8468650,
          "sourceType": "datasetVersion",
          "datasetId": 5049372
        },
        {
          "sourceId": 8468929,
          "sourceType": "datasetVersion",
          "datasetId": 5049571
        },
        {
          "sourceId": 8519425,
          "sourceType": "datasetVersion",
          "datasetId": 5086595
        },
        {
          "sourceId": 8519560,
          "sourceType": "datasetVersion",
          "datasetId": 5086703
        }
      ],
      "dockerImageVersionId": 30068,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shobrunjb/scenario-1---single-task/blob/main/draft-03-singletask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "alMCVgJJAxOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading Essential libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%config Completer.use_jedi = False # this to force autocompletion"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:17.700381Z",
          "iopub.execute_input": "2024-05-27T23:37:17.700655Z",
          "iopub.status.idle": "2024-05-27T23:37:17.723728Z",
          "shell.execute_reply.started": "2024-05-27T23:37:17.700627Z",
          "shell.execute_reply": "2024-05-27T23:37:17.722862Z"
        },
        "trusted": true,
        "id": "zkYh0NDqAxOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/20-review-fake/20 mayfake reviews dataset.csv',)\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:17.724803Z",
          "iopub.execute_input": "2024-05-27T23:37:17.725099Z",
          "iopub.status.idle": "2024-05-27T23:37:18.044046Z",
          "shell.execute_reply.started": "2024-05-27T23:37:17.725072Z",
          "shell.execute_reply": "2024-05-27T23:37:18.043200Z"
        },
        "trusted": true,
        "id": "d2acW7otAxOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['category'])\n",
        "df = df.drop(columns=['rating'])\n",
        "df.info()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:18.045279Z",
          "iopub.execute_input": "2024-05-27T23:37:18.045539Z",
          "iopub.status.idle": "2024-05-27T23:37:18.067686Z",
          "shell.execute_reply.started": "2024-05-27T23:37:18.045514Z",
          "shell.execute_reply": "2024-05-27T23:37:18.066717Z"
        },
        "trusted": true,
        "id": "FSsi5vLMAxOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:18.070521Z",
          "iopub.execute_input": "2024-05-27T23:37:18.070875Z",
          "iopub.status.idle": "2024-05-27T23:37:18.077957Z",
          "shell.execute_reply.started": "2024-05-27T23:37:18.070840Z",
          "shell.execute_reply": "2024-05-27T23:37:18.077110Z"
        },
        "trusted": true,
        "id": "f32Uh15eAxOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "H6uPW2BVAxOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label\"].loc[df[\"label\"]==\"OR\"]=0.0\n",
        "df[\"label\"].loc[df[\"label\"]==\"CG\"]=1.0\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:18.080458Z",
          "iopub.execute_input": "2024-05-27T23:37:18.080744Z",
          "iopub.status.idle": "2024-05-27T23:37:18.106062Z",
          "shell.execute_reply.started": "2024-05-27T23:37:18.080716Z",
          "shell.execute_reply": "2024-05-27T23:37:18.105372Z"
        },
        "trusted": true,
        "id": "Ky0baHMvAxOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set()\n",
        "sns.countplot(df.label)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:18.107376Z",
          "iopub.execute_input": "2024-05-27T23:37:18.107641Z",
          "iopub.status.idle": "2024-05-27T23:37:18.992632Z",
          "shell.execute_reply.started": "2024-05-27T23:37:18.107614Z",
          "shell.execute_reply": "2024-05-27T23:37:18.991631Z"
        },
        "trusted": true,
        "id": "WZPWzmttAxOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['word_length'] = df['text_'].apply(lambda x:len(x.split()))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:18.994002Z",
          "iopub.execute_input": "2024-05-27T23:37:18.994376Z",
          "iopub.status.idle": "2024-05-27T23:37:19.189209Z",
          "shell.execute_reply.started": "2024-05-27T23:37:18.994339Z",
          "shell.execute_reply": "2024-05-27T23:37:19.188404Z"
        },
        "trusted": true,
        "id": "RZ8XvPDdAxOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "df[df.label== 0 ].word_length.plot(bins=35, kind='hist', color='blue',\n",
        "                                       label='Origial Review', alpha=0.6)\n",
        "df[df.label == 1 ].word_length.plot(kind='hist', color='red',\n",
        "                                       label='Fake Review', alpha=0.6)\n",
        "plt.legend()\n",
        "plt.xlabel(\"Message Length\")\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:19.190532Z",
          "iopub.execute_input": "2024-05-27T23:37:19.190830Z",
          "iopub.status.idle": "2024-05-27T23:37:19.731407Z",
          "shell.execute_reply.started": "2024-05-27T23:37:19.190802Z",
          "shell.execute_reply": "2024-05-27T23:37:19.730432Z"
        },
        "trusted": true,
        "id": "LjfVR1grAxOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('label').mean()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:19.732707Z",
          "iopub.execute_input": "2024-05-27T23:37:19.733103Z",
          "iopub.status.idle": "2024-05-27T23:37:19.753017Z",
          "shell.execute_reply.started": "2024-05-27T23:37:19.733064Z",
          "shell.execute_reply": "2024-05-27T23:37:19.752194Z"
        },
        "trusted": true,
        "id": "X0hb1xrDAxOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# describing the hame(normal msgs )\n",
        "df[df.label == 0].describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:19.754544Z",
          "iopub.execute_input": "2024-05-27T23:37:19.754802Z",
          "iopub.status.idle": "2024-05-27T23:37:19.777446Z",
          "shell.execute_reply.started": "2024-05-27T23:37:19.754777Z",
          "shell.execute_reply": "2024-05-27T23:37:19.776629Z"
        },
        "trusted": true,
        "id": "Hm5swjukAxOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Describing  the spam msgs\n",
        "df[df.label == 1].describe()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:19.778382Z",
          "iopub.execute_input": "2024-05-27T23:37:19.778636Z",
          "iopub.status.idle": "2024-05-27T23:37:19.798095Z",
          "shell.execute_reply.started": "2024-05-27T23:37:19.778612Z",
          "shell.execute_reply": "2024-05-27T23:37:19.797399Z"
        },
        "trusted": true,
        "id": "W3D8h3LfAxOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From here we can say that the longer text are more probable to become Spam msgs**"
      ],
      "metadata": {
        "id": "goIvdUgyAxOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### now let do some text_preprocessing"
      ],
      "metadata": {
        "id": "C-CHhicNAxOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install text-hammer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:19.799576Z",
          "iopub.execute_input": "2024-05-27T23:37:19.799911Z",
          "iopub.status.idle": "2024-05-27T23:37:28.600371Z",
          "shell.execute_reply.started": "2024-05-27T23:37:19.799878Z",
          "shell.execute_reply": "2024-05-27T23:37:28.599272Z"
        },
        "trusted": true,
        "id": "R31MRyvrAxOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import text_hammer as th"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:28.601909Z",
          "iopub.execute_input": "2024-05-27T23:37:28.602200Z",
          "iopub.status.idle": "2024-05-27T23:37:32.598787Z",
          "shell.execute_reply.started": "2024-05-27T23:37:28.602170Z",
          "shell.execute_reply": "2024-05-27T23:37:32.597865Z"
        },
        "trusted": true,
        "id": "_k8dpJwRAxOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "tqdm_notebook.pandas()\n",
        "\n",
        "def text_preprocessing(df,col_name):\n",
        "    column = col_name\n",
        "    df[column] = df[column].progress_apply(lambda x:str(x).lower())\n",
        "    df[column] = df[column].progress_apply(lambda x: th.cont_exp(x)) #you're -> you are; i'm -> i am\n",
        "    df[column] = df[column].progress_apply(lambda x: th.remove_emails(x))\n",
        "    df[column] = df[column].progress_apply(lambda x: th.remove_html_tags(x))\n",
        "    df[column] = df[column].progress_apply(lambda x: th.remove_stopwords(x))\n",
        "#     df[column] = df[column].progress_apply(lambda x:th.spelling_correction(x))\n",
        "\n",
        "    df[column] = df[column].progress_apply(lambda x: th.remove_special_chars(x))\n",
        "    df[column] = df[column].progress_apply(lambda x: th.remove_accented_chars(x))\n",
        "    df[column] = df[column].progress_apply(lambda x: th.make_base(x)) #ran -> run,\n",
        "    return(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:32.600203Z",
          "iopub.execute_input": "2024-05-27T23:37:32.600501Z",
          "iopub.status.idle": "2024-05-27T23:37:32.608512Z",
          "shell.execute_reply.started": "2024-05-27T23:37:32.600472Z",
          "shell.execute_reply": "2024-05-27T23:37:32.607696Z"
        },
        "trusted": true,
        "id": "B_E7CtzeAxOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = text_preprocessing(df, \"text_\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:37:32.609735Z",
          "iopub.execute_input": "2024-05-27T23:37:32.610018Z",
          "iopub.status.idle": "2024-05-27T23:46:51.940630Z",
          "shell.execute_reply.started": "2024-05-27T23:37:32.609988Z",
          "shell.execute_reply": "2024-05-27T23:46:51.939816Z"
        },
        "trusted": true,
        "id": "AJy1DdFpAxOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df.text_"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:46:51.941963Z",
          "iopub.execute_input": "2024-05-27T23:46:51.942256Z",
          "iopub.status.idle": "2024-05-27T23:46:51.949667Z",
          "shell.execute_reply.started": "2024-05-27T23:46:51.942226Z",
          "shell.execute_reply": "2024-05-27T23:46:51.948634Z"
        },
        "trusted": true,
        "id": "jTwfgBYJAxOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now lets do some EDA"
      ],
      "metadata": {
        "id": "Bb5zxOC7AxOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "\n",
        "\n",
        "### Calculating the word frequency by using nltk\n",
        "words_list = []\n",
        "for sentence in cleaned_df.text_:\n",
        "    words_list.extend(nltk.word_tokenize(sentence))\n",
        "freq_dist = nltk.FreqDist(words_list)\n",
        "freq_dist.most_common(20)\n",
        "# freq_dist.keys()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:46:51.951068Z",
          "iopub.execute_input": "2024-05-27T23:46:51.951467Z",
          "iopub.status.idle": "2024-05-27T23:47:05.598350Z",
          "shell.execute_reply.started": "2024-05-27T23:46:51.951429Z",
          "shell.execute_reply": "2024-05-27T23:47:05.597492Z"
        },
        "trusted": true,
        "id": "DTQ0p_DkAxOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = pd.DataFrame(freq_dist.most_common(30),  columns=['word', 'count'])\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "sns.barplot(x='word', y='count',\n",
        "            data=temp, ax=ax)\n",
        "plt.title(\"Top words\")\n",
        "plt.xticks(rotation='vertical');"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:05.599754Z",
          "iopub.execute_input": "2024-05-27T23:47:05.600042Z",
          "iopub.status.idle": "2024-05-27T23:47:06.204730Z",
          "shell.execute_reply.started": "2024-05-27T23:47:05.600012Z",
          "shell.execute_reply": "2024-05-27T23:47:06.203859Z"
        },
        "trusted": true,
        "id": "u7mPq8ykAxOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Creating wordcloud\n",
        "from wordcloud import WordCloud\n",
        "import wordcloud\n",
        "# creation of wordcloud\n",
        "wcloud_fig = WordCloud( stopwords=set(wordcloud.STOPWORDS),\n",
        "                      colormap='viridis', width=300, height=200).generate_from_frequencies(freq_dist)\n",
        "\n",
        "# plotting the wordcloud\n",
        "plt.figure(figsize=(10,7), frameon=True)\n",
        "\n",
        "plt.imshow(wcloud_fig, interpolation  = 'bilinear')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:06.206170Z",
          "iopub.execute_input": "2024-05-27T23:47:06.206520Z",
          "iopub.status.idle": "2024-05-27T23:47:07.138382Z",
          "shell.execute_reply.started": "2024-05-27T23:47:06.206483Z",
          "shell.execute_reply": "2024-05-27T23:47:07.137420Z"
        },
        "trusted": true,
        "id": "pUf5OLFRAxOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Module 2\n",
        "#### till now we have done all text cleaning and plottting part"
      ],
      "metadata": {
        "id": "jMmFBJM_AxOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### now lets split our data for some training and testing"
      ],
      "metadata": {
        "id": "6HfIgjQjAxOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test, y_train,y_test = train_test_split(cleaned_df.text_, cleaned_df.label, test_size = 0.2, stratify = cleaned_df.label\n",
        "                                                 ,random_state = 42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:07.139539Z",
          "iopub.execute_input": "2024-05-27T23:47:07.139797Z",
          "iopub.status.idle": "2024-05-27T23:47:07.223819Z",
          "shell.execute_reply.started": "2024-05-27T23:47:07.139771Z",
          "shell.execute_reply": "2024-05-27T23:47:07.223109Z"
        },
        "trusted": true,
        "id": "qqfXjPnkAxOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using The tokenizer Class to convert the sentences into word vectorsÂ¶\n"
      ],
      "metadata": {
        "id": "sYmkfv-5AxOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "num_words = 5000 # this means 15000 unique words can be taken\n",
        "tokenizer=Tokenizer(num_words,lower=True)\n",
        "df_total = pd.concat([X_train, X_test], axis = 0)\n",
        "tokenizer.fit_on_texts(df_total)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:07.224868Z",
          "iopub.execute_input": "2024-05-27T23:47:07.225116Z",
          "iopub.status.idle": "2024-05-27T23:47:13.917546Z",
          "shell.execute_reply.started": "2024-05-27T23:47:07.225091Z",
          "shell.execute_reply": "2024-05-27T23:47:13.916795Z"
        },
        "trusted": true,
        "id": "M9rCqzQZAxOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index) # this is whole unique words in our corpus\n",
        "# but we have taken 10000 but we have only 8502 and the rest will be zero"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:13.918850Z",
          "iopub.execute_input": "2024-05-27T23:47:13.919121Z",
          "iopub.status.idle": "2024-05-27T23:47:13.923876Z",
          "shell.execute_reply.started": "2024-05-27T23:47:13.919095Z",
          "shell.execute_reply": "2024-05-27T23:47:13.923108Z"
        },
        "trusted": true,
        "id": "GDzkR_FVAxOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df.word_length.max()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:13.924877Z",
          "iopub.execute_input": "2024-05-27T23:47:13.925202Z",
          "iopub.status.idle": "2024-05-27T23:47:13.937129Z",
          "shell.execute_reply.started": "2024-05-27T23:47:13.925174Z",
          "shell.execute_reply": "2024-05-27T23:47:13.936419Z"
        },
        "trusted": true,
        "id": "NSG_BK91AxOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_ =tokenizer.texts_to_sequences(X_train)\n",
        "X_test_ = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:13.938395Z",
          "iopub.execute_input": "2024-05-27T23:47:13.938742Z",
          "iopub.status.idle": "2024-05-27T23:47:15.290544Z",
          "shell.execute_reply.started": "2024-05-27T23:47:13.938706Z",
          "shell.execute_reply": "2024-05-27T23:47:15.289753Z"
        },
        "trusted": true,
        "id": "p2EoTSPbAxOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad=pad_sequences(X_train_,maxlen=171,padding='post')\n",
        "X_test_pad = pad_sequences(X_test_, maxlen = 171, padding = 'post')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:15.291698Z",
          "iopub.execute_input": "2024-05-27T23:47:15.291962Z",
          "iopub.status.idle": "2024-05-27T23:47:15.720885Z",
          "shell.execute_reply.started": "2024-05-27T23:47:15.291929Z",
          "shell.execute_reply": "2024-05-27T23:47:15.720208Z"
        },
        "trusted": true,
        "id": "uZYewU6YAxOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pad = X_train_pad.astype(np.float32)\n",
        "X_test_pad = X_test_pad.astype(np.float32)\n",
        "y_train = np.array(y_train).astype(np.int32)\n",
        "y_test = np.array(y_test).astype(np.int32)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:15.722140Z",
          "iopub.execute_input": "2024-05-27T23:47:15.722522Z",
          "iopub.status.idle": "2024-05-27T23:47:15.741604Z",
          "shell.execute_reply.started": "2024-05-27T23:47:15.722481Z",
          "shell.execute_reply": "2024-05-27T23:47:15.740934Z"
        },
        "trusted": true,
        "id": "qvkusMzDAxOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_pad.shape,X_test_pad.shape) # this is our 2D matrix we can take this as Input data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:15.742890Z",
          "iopub.execute_input": "2024-05-27T23:47:15.743205Z",
          "iopub.status.idle": "2024-05-27T23:47:15.747209Z",
          "shell.execute_reply.started": "2024-05-27T23:47:15.743168Z",
          "shell.execute_reply": "2024-05-27T23:47:15.746492Z"
        },
        "trusted": true,
        "id": "SS6nMqfoAxOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now lets design our Deep learning model to train our data"
      ],
      "metadata": {
        "id": "yXFRhy20AxOK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method1: by using solely embedding layers"
      ],
      "metadata": {
        "id": "KBnIfBVNAxOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding,Bidirectional\n",
        "import tensorflow\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM,CuDNNGRU\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:15.748477Z",
          "iopub.execute_input": "2024-05-27T23:47:15.748833Z",
          "iopub.status.idle": "2024-05-27T23:47:15.819023Z",
          "shell.execute_reply.started": "2024-05-27T23:47:15.748797Z",
          "shell.execute_reply": "2024-05-27T23:47:15.818257Z"
        },
        "trusted": true,
        "id": "Hjwuw-BxAxOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100 # this means the embedding layer will create  a vector in 100 dimension\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = num_words,# the whole vocabulary size\n",
        "                          output_dim = EMBEDDING_DIM, # vector space dimension\n",
        "                          input_length= X_train_pad.shape[1] # max_len of text sequence\n",
        "                          ))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(CuDNNLSTM(100,return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(CuDNNLSTM(200,return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(CuDNNLSTM(100,return_sequences=False)))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam',metrics = 'accuracy')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:15.820585Z",
          "iopub.execute_input": "2024-05-27T23:47:15.821088Z",
          "iopub.status.idle": "2024-05-27T23:47:18.592174Z",
          "shell.execute_reply.started": "2024-05-27T23:47:15.821049Z",
          "shell.execute_reply": "2024-05-27T23:47:18.591154Z"
        },
        "trusted": true,
        "id": "3lQytRXcAxOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EarlyStopping and ModelCheckpoint\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 10)\n",
        "mc = ModelCheckpoint('./model.h5', monitor = 'val_accuracy', mode = 'max', verbose = 1, save_best_only = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:18.593455Z",
          "iopub.execute_input": "2024-05-27T23:47:18.593759Z",
          "iopub.status.idle": "2024-05-27T23:47:18.598725Z",
          "shell.execute_reply.started": "2024-05-27T23:47:18.593717Z",
          "shell.execute_reply": "2024-05-27T23:47:18.597739Z"
        },
        "trusted": true,
        "id": "cpUehXGkAxOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_embedding = model.fit(X_train_pad,y_train, epochs = 35, batch_size = 120, validation_data=(X_test_pad, y_test),verbose = 1, callbacks= [es, mc]  )\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:47:18.604222Z",
          "iopub.execute_input": "2024-05-27T23:47:18.604558Z",
          "iopub.status.idle": "2024-05-27T23:53:54.482992Z",
          "shell.execute_reply.started": "2024-05-27T23:47:18.604529Z",
          "shell.execute_reply": "2024-05-27T23:53:54.482205Z"
        },
        "trusted": true,
        "id": "BICwbaQrAxOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history_embedding.history['accuracy'],c='b',label='train accuracy')\n",
        "plt.plot(history_embedding.history['val_accuracy'],c='r',label='validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:53:54.484430Z",
          "iopub.execute_input": "2024-05-27T23:53:54.484695Z",
          "iopub.status.idle": "2024-05-27T23:53:54.725588Z",
          "shell.execute_reply.started": "2024-05-27T23:53:54.484668Z",
          "shell.execute_reply": "2024-05-27T23:53:54.724841Z"
        },
        "trusted": true,
        "id": "9VyMor5xAxOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### the maximum accurary we have got with wordembedding is 98 with some overfitting  now we would try with word2vec"
      ],
      "metadata": {
        "id": "a_kMn63kAxOK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 2: Using word2vec **i'm gonna use gensim **"
      ],
      "metadata": {
        "id": "3kpMmSZHAxOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "glove_gensim  = api.load('glove-wiki-gigaword-100') # this would download vector with 100 dimension"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:53:54.726752Z",
          "iopub.execute_input": "2024-05-27T23:53:54.727011Z",
          "iopub.status.idle": "2024-05-27T23:55:22.968497Z",
          "shell.execute_reply.started": "2024-05-27T23:53:54.726985Z",
          "shell.execute_reply": "2024-05-27T23:55:22.967556Z"
        },
        "trusted": true,
        "id": "g9E8cqEhAxOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_gensim['cat'].shape[0] # this is the diemnsion of the vectors"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:55:22.969847Z",
          "iopub.execute_input": "2024-05-27T23:55:22.970227Z",
          "iopub.status.idle": "2024-05-27T23:55:22.976498Z",
          "shell.execute_reply.started": "2024-05-27T23:55:22.970188Z",
          "shell.execute_reply": "2024-05-27T23:55:22.975519Z"
        },
        "trusted": true,
        "id": "nL3nJKGMAxOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now lets connvert all the words we have in our data into vectors\n",
        "vector_size = 100\n",
        "gensim_weight_matrix = np.zeros((num_words ,vector_size))\n",
        "gensim_weight_matrix.shape\n",
        "\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index < num_words: # since index starts with zero\n",
        "        if word in glove_gensim.wv.vocab:\n",
        "            gensim_weight_matrix[index] = glove_gensim[word]\n",
        "        else:\n",
        "            gensim_weight_matrix[index] = np.zeros(100)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:55:22.977807Z",
          "iopub.execute_input": "2024-05-27T23:55:22.978170Z",
          "iopub.status.idle": "2024-05-27T23:55:23.044190Z",
          "shell.execute_reply.started": "2024-05-27T23:55:22.978119Z",
          "shell.execute_reply": "2024-05-27T23:55:23.043585Z"
        },
        "trusted": true,
        "id": "MNs_x88xAxOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gensim_weight_matrix.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:55:23.045134Z",
          "iopub.execute_input": "2024-05-27T23:55:23.045437Z",
          "iopub.status.idle": "2024-05-27T23:55:23.049966Z",
          "shell.execute_reply.started": "2024-05-27T23:55:23.045408Z",
          "shell.execute_reply": "2024-05-27T23:55:23.049286Z"
        },
        "trusted": true,
        "id": "D6RxzqUbAxOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# designing our architecture\n",
        "EMBEDDING_DIM = 100 # this means the embedding layer will create  a vector in 100 dimension\n",
        "model_gensim = Sequential()\n",
        "model_gensim.add(Embedding(input_dim = num_words,# the whole vocabulary size\n",
        "                          output_dim = EMBEDDING_DIM, # vector space dimension\n",
        "                          input_length= X_train_pad.shape[1], # max_len of text sequence\n",
        "                          weights = [gensim_weight_matrix],trainable = False))\n",
        "model_gensim.add(Dropout(0.2))\n",
        "model_gensim.add(Bidirectional(CuDNNLSTM(100,return_sequences=True)))\n",
        "model_gensim.add(Dropout(0.2))\n",
        "model_gensim.add(Bidirectional(CuDNNLSTM(200,return_sequences=True)))\n",
        "model_gensim.add(Dropout(0.2))\n",
        "model_gensim.add(Bidirectional(CuDNNLSTM(100,return_sequences=False)))\n",
        "model_gensim.add(Dense(1, activation = 'sigmoid'))\n",
        "model_gensim.compile(loss = 'binary_crossentropy', optimizer = 'adam',metrics = 'accuracy')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:55:23.051430Z",
          "iopub.execute_input": "2024-05-27T23:55:23.051705Z",
          "iopub.status.idle": "2024-05-27T23:55:23.529536Z",
          "shell.execute_reply.started": "2024-05-27T23:55:23.051678Z",
          "shell.execute_reply": "2024-05-27T23:55:23.528536Z"
        },
        "trusted": true,
        "id": "Ksd4iqr2AxOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gensim.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:55:23.530759Z",
          "iopub.execute_input": "2024-05-27T23:55:23.531065Z",
          "iopub.status.idle": "2024-05-27T23:55:23.539294Z",
          "shell.execute_reply.started": "2024-05-27T23:55:23.531035Z",
          "shell.execute_reply": "2024-05-27T23:55:23.538065Z"
        },
        "trusted": true,
        "id": "pahI_6xaAxOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5)\n",
        "mc = ModelCheckpoint('./model_gensim.h5', monitor = 'val_accuracy', mode = 'max', verbose = 1, save_best_only = True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:55:23.540268Z",
          "iopub.execute_input": "2024-05-27T23:55:23.540585Z",
          "iopub.status.idle": "2024-05-27T23:55:23.548979Z",
          "shell.execute_reply.started": "2024-05-27T23:55:23.540556Z",
          "shell.execute_reply": "2024-05-27T23:55:23.548095Z"
        },
        "trusted": true,
        "id": "lHWMQPxiAxOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_gensim = model_gensim.fit(X_train_pad,y_train, epochs = 25, batch_size = 120, validation_data=(X_test_pad, y_test),verbose = 1, callbacks= [es, mc]  )\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T23:55:23.550071Z",
          "iopub.execute_input": "2024-05-27T23:55:23.550387Z",
          "iopub.status.idle": "2024-05-28T00:02:24.562186Z",
          "shell.execute_reply.started": "2024-05-27T23:55:23.550360Z",
          "shell.execute_reply": "2024-05-28T00:02:24.561305Z"
        },
        "trusted": true,
        "id": "6t3bRHF0AxOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets draw learning curve\n",
        "\n",
        "plt.plot(history_gensim.history['accuracy'],c='b',label='train accuracy')\n",
        "plt.plot(history_gensim.history['val_accuracy'],c='r',label='validation accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-28T00:02:24.563591Z",
          "iopub.execute_input": "2024-05-28T00:02:24.563864Z",
          "iopub.status.idle": "2024-05-28T00:02:24.794968Z",
          "shell.execute_reply.started": "2024-05-28T00:02:24.563838Z",
          "shell.execute_reply": "2024-05-28T00:02:24.794101Z"
        },
        "trusted": true,
        "id": "BXE1Jc6OAxOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **model trained with word2vec is more generalised model so we will choose that as our final model **"
      ],
      "metadata": {
        "id": "tNjiJiDzAxOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_gensim.evaluate(X_test_pad, y_test)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-28T00:02:24.796049Z",
          "iopub.execute_input": "2024-05-28T00:02:24.796341Z",
          "iopub.status.idle": "2024-05-28T00:02:41.886299Z",
          "shell.execute_reply.started": "2024-05-28T00:02:24.796311Z",
          "shell.execute_reply": "2024-05-28T00:02:41.885451Z"
        },
        "trusted": true,
        "id": "xME2363mAxOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_pad, y_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-28T00:02:41.887536Z",
          "iopub.execute_input": "2024-05-28T00:02:41.887888Z",
          "iopub.status.idle": "2024-05-28T00:02:48.487178Z",
          "shell.execute_reply.started": "2024-05-28T00:02:41.887857Z",
          "shell.execute_reply": "2024-05-28T00:02:48.486269Z"
        },
        "trusted": true,
        "id": "aDGzSUfMAxOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation"
      ],
      "metadata": {
        "id": "RJkkh1ywAxOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.where(model.predict(X_test_pad)>.5,1,0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-28T00:02:48.488408Z",
          "iopub.execute_input": "2024-05-28T00:02:48.488766Z",
          "iopub.status.idle": "2024-05-28T00:02:55.743967Z",
          "shell.execute_reply.started": "2024-05-28T00:02:48.488735Z",
          "shell.execute_reply": "2024-05-28T00:02:55.743118Z"
        },
        "trusted": true,
        "id": "k3TFNY9DAxOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "print(metrics.classification_report(y_pred, y_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-28T00:02:55.745367Z",
          "iopub.execute_input": "2024-05-28T00:02:55.745732Z",
          "iopub.status.idle": "2024-05-28T00:02:55.767839Z",
          "shell.execute_reply.started": "2024-05-28T00:02:55.745692Z",
          "shell.execute_reply": "2024-05-28T00:02:55.767041Z"
        },
        "trusted": true,
        "id": "xp6K0XDDAxOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_gensim = np.where(model_gensim.predict(X_test_pad)>0.5,1,0)\n",
        "print(metrics.classification_report(y_pred_gensim, y_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-28T00:02:55.768796Z",
          "iopub.execute_input": "2024-05-28T00:02:55.769051Z",
          "iopub.status.idle": "2024-05-28T00:03:02.792107Z",
          "shell.execute_reply.started": "2024-05-28T00:02:55.769026Z",
          "shell.execute_reply": "2024-05-28T00:03:02.791138Z"
        },
        "trusted": true,
        "id": "o60NCgZcAxON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now lets test our model with real data"
      ],
      "metadata": {
        "id": "HKBWRWyiAxON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence):\n",
        "    sentence_lst=[]\n",
        "    sentence_lst.append(sentence)\n",
        "    sentence_seq=tokenizer.texts_to_sequences(sentence_lst)\n",
        "    sentence_padded=pad_sequences(sentence_seq,maxlen=171,padding='post')\n",
        "    probability = (model_gensim.predict(sentence_padded))[0][0]\n",
        "    if probability > 0.5:\n",
        "        print(f'Fake Review | {np.round(probability*100,2)}%')\n",
        "    else:\n",
        "        print(f'Original Review | {100 - (np.round(probability*100,2))}%')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-28T00:07:01.523559Z",
          "iopub.execute_input": "2024-05-28T00:07:01.523886Z",
          "iopub.status.idle": "2024-05-28T00:07:01.529648Z",
          "shell.execute_reply.started": "2024-05-28T00:07:01.523857Z",
          "shell.execute_reply": "2024-05-28T00:07:01.528769Z"
        },
        "trusted": true,
        "id": "C4-dCWdCAxON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(str(input('Enter the Sentence:')))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-28T00:07:04.645921Z",
          "iopub.execute_input": "2024-05-28T00:07:04.646281Z",
          "iopub.status.idle": "2024-05-28T00:07:07.454842Z",
          "shell.execute_reply.started": "2024-05-28T00:07:04.646246Z",
          "shell.execute_reply": "2024-05-28T00:07:07.453759Z"
        },
        "trusted": true,
        "id": "PGrgJfXEAxON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(str(input('Enter the Sentence:')))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-28T00:07:10.855922Z",
          "iopub.execute_input": "2024-05-28T00:07:10.856277Z",
          "iopub.status.idle": "2024-05-28T00:07:14.821890Z",
          "shell.execute_reply.started": "2024-05-28T00:07:10.856245Z",
          "shell.execute_reply": "2024-05-28T00:07:14.820965Z"
        },
        "trusted": true,
        "id": "aiO3usgxAxON"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}